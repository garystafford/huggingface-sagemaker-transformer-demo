{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02472706-e24d-4074-abcc-060408757621",
   "metadata": {},
   "source": [
    "# Task Specific Transformer Model Demo\n",
    "\n",
    "## English-to-Chinese Translation\n",
    "\n",
    "- Model: `Helsinki-NLP/opus-mt-en-zh`\n",
    "- Hugging Face: https://huggingface.co/Helsinki-NLP/opus-mt-en-zh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9b893b-91f9-4f23-ab5a-649e15b58e58",
   "metadata": {},
   "source": [
    "## Deploy Required Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00baf41b-ff57-46ce-aae7-9f8b23572248",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "python3 -m pip install sagemaker boto3 botocore jsonlines -Uq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2a4394-2044-4683-a0bc-956b790f2d2e",
   "metadata": {},
   "source": [
    "## Deploy Hugging Face Model to SageMaker\n",
    "\n",
    "Deploy the Hugging Face model to an Amazon SageMaker real-time inference endpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b2a399-be33-4789-8d39-bd7281450603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model used throughout the demonstration\n",
    "HF_MODEL_ID = \"Helsinki-NLP/opus-mt-en-zh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2504b5-8095-4185-b4d3-1f4273181463",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    client_iam = boto3.client(\"iam\")\n",
    "    role = client_iam.get_role(RoleName=\"sagemaker_execution_role\")[\"Role\"][\"Arn\"]\n",
    "\n",
    "# hub model configuration. https://huggingface.co/models\n",
    "hub = {\"HF_MODEL_ID\": HF_MODEL_ID, \"HF_TASK\": \"translation\"}\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "    transformers_version=\"4.37.0\",\n",
    "    pytorch_version=\"2.1.0\",\n",
    "    py_version=\"py310\",\n",
    "    env=hub,\n",
    "    role=role,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6397f7-1a4c-4545-bcc4-b04ef28902df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1x to deploy model to SageMaker real-time inference endpoint\n",
    "\n",
    "predictor = huggingface_model.deploy(\n",
    "    initial_instance_count=1,  # number of instances\n",
    "    instance_type=\"ml.g5.12xlarge\",  # ec2 instance type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3b7a9a-2171-484e-a263-3ec89896dabb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# output contains real-time inference endpoint name\n",
    "\n",
    "predictor.endpoint_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83f3859-bd33-451e-a4c3-3c1e3c310b27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "predictor.predict(\n",
    "    {\n",
    "        \"inputs\": \"A heart filled with anger has no room for love.\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf152a8-222e-4551-ba1b-74a6730de650",
   "metadata": {},
   "source": [
    "## Selecting an Existing SageMaker Endpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c08a7ba-fc9c-4c72-956e-6fb5a0c0f30f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# deployed model real-time inference endpoint\n",
    "SAGEMAKER_ENDPOINT = \"<your_sagemaker_realtime_endpoint>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb053c1c-cef5-4263-a58b-c9f04a58bd0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.huggingface.model import HuggingFacePredictor\n",
    "\n",
    "session = sagemaker.session.Session()\n",
    "\n",
    "predictor = HuggingFacePredictor(\n",
    "    endpoint_name=SAGEMAKER_ENDPOINT, sagemaker_session=session\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac222f2b-a889-47b7-a96a-6ce6f987c0fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "predictor.predict(\n",
    "    {\n",
    "        \"inputs\": \"A heart filled with anger has no room for love.\",\n",
    "        \"parameters\": {\"max_length\": 1024, \"min_length\": 1},\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511e18ad-3421-4524-99f8-ffbd9e4612a7",
   "metadata": {},
   "source": [
    "## Using SageMaker Runtime Client for Inference\n",
    "\n",
    "- Reference: <https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker-runtime/client/invoke_endpoint.html>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb4f57c-7551-4739-874e-a905dba394fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import boto3\n",
    "\n",
    "client_smr = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "response = client_smr.invoke_endpoint(\n",
    "    EndpointName=SAGEMAKER_ENDPOINT,\n",
    "    Body=bytes(\n",
    "        '{\"inputs\": \"A heart filled with anger has no room for love.\"}', \"utf-8\"\n",
    "    ),\n",
    "    ContentType=\"application/json\",\n",
    ")\n",
    "\n",
    "# decodes and prints the response body:\n",
    "print(response[\"Body\"].read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7c6f68-abb4-40fd-a849-ab54e84481d3",
   "metadata": {},
   "source": [
    "## Kaggle Dataset\n",
    "\n",
    "`Quotes - 500k`\n",
    "\n",
    "Description: \"_The dataset is offered in CSV file format and contains three columns --- the quote, the author of the quote and the category tags for that quote. Examples of tags include --- love, life, philosophy, motivation, family, etc. These tags help in describing the various categories that a particular quote belongs to._\"\n",
    "\n",
    "Link: https://www.kaggle.com/datasets/manann/quotes-500k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e265dd-a7a7-4427-a387-fc6ea5849330",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "file = open(\"./_prelims/quotes_10k_clean.csv\", \"r\")\n",
    "data = list(csv.reader(file, delimiter=\",\"))\n",
    "file.close()\n",
    "\n",
    "quotes = []\n",
    "for idx, row in enumerate(data):\n",
    "    # skip longer quotes that cause errors with model inference (\"model_max_length\": 512 tokens)\n",
    "    if len(row[0]) > 1024:\n",
    "        continue\n",
    "    quotes.append(row)\n",
    "\n",
    "print(len(quotes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ee4446-6938-4d4c-ab03-976ef317bcb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create lists of quotes of different sizes for testing\n",
    "# skip headers on the first row\n",
    "\n",
    "import json\n",
    "\n",
    "quotes_10 = [column[0] for column in quotes[1:11]]\n",
    "quotes_100 = [column[0] for column in quotes[1:101]]\n",
    "quotes_1k = [column[0] for column in quotes[1:1001]]\n",
    "quotes_10k = [column[0] for column in quotes[1:10001]]\n",
    "\n",
    "print(len(quotes_10))\n",
    "print(json.dumps(quotes_10[0:3], ensure_ascii=False, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ed3ff7-3e82-4a40-b59e-75fd34b2d6b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculate count and mean length of quotes\n",
    "\n",
    "total_length = 0\n",
    "\n",
    "for quote in quotes_10k:\n",
    "    total_length += len(quote)\n",
    "\n",
    "print(f\"total length: {total_length}\")\n",
    "print(f\"# of quotes: {len(quotes_10k)}\")\n",
    "print(f\"avg. length of quotes: {round(total_length / len(quotes_10k))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c6b570-0e6c-46c8-8080-50eeeb233e8d",
   "metadata": {},
   "source": [
    "## Batch Inference using a Real-time Endpoint\n",
    "\n",
    "Perform real-time inference on list of quotes, sequentially, using a loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc750bc-756f-45db-bb8f-d7540cde75de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import time\n",
    "import boto3\n",
    "\n",
    "client_smr = boto3.client(\"sagemaker-runtime\", region_name=\"us-east-1\")\n",
    "\n",
    "translations = []\n",
    "\n",
    "for idx, quote in enumerate(quotes_1000):\n",
    "    try:\n",
    "        json = f'\"inputs\": \"{quote}\"'\n",
    "        json = \"{\" + json + \"}\"\n",
    "        response = client_smr.invoke_endpoint(\n",
    "            EndpointName=SAGEMAKER_ENDPOINT,\n",
    "            Body=bytes(json, \"utf-8\"),\n",
    "            ContentType=\"application/json\",\n",
    "        )\n",
    "        response_str = response[\"Body\"].read().decode(\"utf-8\")\n",
    "        response_dict = eval(response_str)\n",
    "        translation_text = response_dict[0][\"translation_text\"]\n",
    "        translations.append({\"input\": quote, \"output\": translation_text})\n",
    "    except client_smr.exceptions.ModelError as e:\n",
    "        print(e)\n",
    "\n",
    "    print(f\"Translating quote: {idx}/1000\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0446434-4577-4acd-bd64-b2112ee14ad0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "print(len(translations))\n",
    "print(json.dumps(translations[0:3], ensure_ascii=False, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba1c61a-6d0f-403f-945d-fc90ff37493a",
   "metadata": {},
   "source": [
    "## Batch Transforms\n",
    "\n",
    "Instance type for batch transforms must be one of the following types:\n",
    "\n",
    "```txt\n",
    "'InstanceType': 'ml.m4.xlarge'|'ml.m4.2xlarge'|'ml.m4.4xlarge'|'ml.m4.10xlarge'|\n",
    "'ml.m4.16xlarge'|'ml.c4.xlarge'|'ml.c4.2xlarge'|'ml.c4.4xlarge'|'ml.c4.8xlarge'|\n",
    "'ml.p2.xlarge'|'ml.p2.8xlarge'|'ml.p2.16xlarge'|'ml.p3.2xlarge'|'ml.p3.8xlarge'|\n",
    "'ml.p3.16xlarge'|'ml.c5.xlarge'|'ml.c5.2xlarge'|'ml.c5.4xlarge'|'ml.c5.9xlarge'|\n",
    "'ml.c5.18xlarge'|'ml.m5.large'|'ml.m5.xlarge'|'ml.m5.2xlarge'|'ml.m5.4xlarge'|\n",
    "'ml.m5.12xlarge'|'ml.m5.24xlarge'|'ml.g4dn.xlarge'|'ml.g4dn.2xlarge'|\n",
    "'ml.g4dn.4xlarge'|'ml.g4dn.8xlarge'|'ml.g4dn.12xlarge'|'ml.g4dn.16xlarge'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb22f44-7239-47fb-b633-5bbd9f6c45e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3 bucket used to store input data and outputs from batch transforms\n",
    "S3_BUCKET = \"<your_s3_bucket_name>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700ff1cc-cb36-4421-a232-8ba69fc9572f",
   "metadata": {},
   "source": [
    "### Write Quotes to JSON Lines Text Format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593fe3e8-a6ea-4e91-a547-609fa5a5e689",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "\n",
    "filename = \"./10k_quotes/quotes_10k_1.jsonl\"\n",
    "\n",
    "items = []\n",
    "\n",
    "for quote in quotes_10k[0:2500]:\n",
    "    items.append({\"inputs\": quote})\n",
    "\n",
    "with jsonlines.open(filename, \"w\") as writer:\n",
    "    writer.write_all(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f747f8a2-6061-4575-97b6-cb33dc7a11ae",
   "metadata": {},
   "source": [
    "### Copy JSON Lines Files to S3\n",
    "\n",
    "The routine below will copy all input data files to your S3 bucket.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91815765-e899-45cc-8268-2ae98d786fad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Uploader, s3_path_join\n",
    "\n",
    "files = [\n",
    "    \"quotes/quotes_10.jsonl\",\n",
    "    \"quotes/quotes_100.jsonl\",\n",
    "    \"quotes/quotes_1k.jsonl\",\n",
    "    \"quotes/quotes_10k.jsonl\",\n",
    "]\n",
    "\n",
    "for file in files:\n",
    "    input_s3_path = s3_path_join(\"s3://\", S3_BUCKET, \"input_batch\", \"quotes\")\n",
    "    s3_file_uri = S3Uploader.upload(file, input_s3_path)\n",
    "    print(f\"{file} uploaded to {s3_file_uri}\")\n",
    "\n",
    "files = [\n",
    "    \"10k_quotes/quotes_10k_1.jsonl\",\n",
    "    \"10k_quotes/quotes_10k_2.jsonl\",\n",
    "    \"10k_quotes/quotes_10k_3.jsonl\",\n",
    "    \"10k_quotes/quotes_10k_4.jsonl\",\n",
    "]\n",
    "\n",
    "for file in files:\n",
    "    input_s3_path = s3_path_join(\"s3://\", S3_BUCKET, \"input_batch\", \"10k_quotes\")\n",
    "    s3_file_uri = S3Uploader.upload(file, input_s3_path)\n",
    "    print(f\"{file} uploaded to {s3_file_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712786ec-c951-4c95-ab76-b5d6b3017748",
   "metadata": {},
   "source": [
    "### Batch Transform with Hugging Face\n",
    "\n",
    "References:\n",
    "\n",
    "- <https://www.philschmid.de/sagemaker-inference-comparison>\n",
    "- <https://huggingface.co/docs/sagemaker/inference#run-batch-transform-with--transformers-and-sagemaker>\n",
    "- <https://discuss.huggingface.co/t/running-batch-transform-in-sagemaker-on-a-huggingface-model-from-the-hub-with-parameters/18390/3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff336f6",
   "metadata": {},
   "source": [
    "#### Multiple file batch of 10,000 quotes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e23c414-8504-4343-8af7-5b61d7837a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    client_iam = boto3.client(\"iam\")\n",
    "    role = client_iam.get_role(RoleName=\"sagemaker_execution_role\")[\"Role\"][\"Arn\"]\n",
    "\n",
    "# Hub model configuration <https://huggingface.co/models>\n",
    "hub = {\"HF_MODEL_ID\": HF_MODEL_ID, \"HF_TASK\": \"translation\"}\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "    transformers_version=\"4.37.0\",\n",
    "    pytorch_version=\"2.1.0\",\n",
    "    py_version=\"py310\",\n",
    "    env=hub,\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "output_s3_path = f\"s3://{S3_BUCKET}/output_batch\"\n",
    "s3_data_input = f\"s3://{S3_BUCKET}/input_batch/10k_quotes/\"\n",
    "\n",
    "# starts batch transform job and uses S3 data as input\n",
    "batch_job = huggingface_model.transformer(\n",
    "    accept=\"application/json\",\n",
    "    assemble_with=\"Line\",\n",
    "    instance_count=2,\n",
    "    instance_type=\"ml.g4dn.8xlarge\",\n",
    "    output_path=output_s3_path,\n",
    "    strategy=\"SingleRecord\",\n",
    ")\n",
    "\n",
    "batch_job.transform(\n",
    "    content_type=\"application/json\",\n",
    "    data=s3_data_input,\n",
    "    split_type=\"Line\",\n",
    "    logs=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee48d6f6-e47c-4679-bb7f-b581cf641f55",
   "metadata": {},
   "source": [
    "### Execute Batch Transform using SageMaker Client\n",
    "\n",
    "- <https://docs.aws.amazon.com/sagemaker/latest/dg/autopilot-deploy-models-batch.html>\n",
    "- <https://github.com/huggingface/notebooks/blob/main/sagemaker/12_batch_transform_inference/sagemaker-notebook.ipynb>\n",
    "- Troubleshooting: <https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform-errors.html>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb76923",
   "metadata": {},
   "source": [
    "#### Single file batch of 1,000 quotes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a40d4d-4204-49f3-85dc-852fd9d2d320",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import time\n",
    "\n",
    "session = sagemaker.session.Session()\n",
    "client_sm = boto3.client(\"sagemaker\", region_name=\"us-east-1\")\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    client_iam = boto3.client(\"iam\")\n",
    "    role = client_iam.get_role(RoleName=\"sagemaker_execution_role\")[\"Role\"][\"Arn\"]\n",
    "\n",
    "output_s3_path = f\"s3://{S3_BUCKET}/output_batch\"\n",
    "s3_data_input = f\"s3://{S3_BUCKET}/input_batch/quotes/quotes_1k.jsonl\"\n",
    "model_name = \"<your_deployed_model_name>\"\n",
    "batch_job_name = f\"quotes-batch-{int(time.time())}-1k\"\n",
    "\n",
    "epoch_time = int(time.time())\n",
    "\n",
    "# launch batch transform job\n",
    "response = client_sm.create_transform_job(\n",
    "    TransformJobName=batch_job_name,\n",
    "    ModelName=model_name,\n",
    "    BatchStrategy=\"SingleRecord\",\n",
    "    TransformInput={\n",
    "        \"DataSource\": {\n",
    "            \"S3DataSource\": {\n",
    "                \"S3DataType\": \"S3Prefix\",\n",
    "                \"S3Uri\": s3_data_input,\n",
    "            }\n",
    "        },\n",
    "        \"ContentType\": \"application/json\",  # file is jsonlines format, but avoiding error.\n",
    "        \"SplitType\": \"Line\",\n",
    "    },\n",
    "    TransformOutput={\n",
    "        \"S3OutputPath\": output_s3_path,\n",
    "        \"AssembleWith\": \"Line\",\n",
    "        \"Accept\": \"application/json\",\n",
    "    },\n",
    "    TransformResources={\n",
    "        \"InstanceType\": \"ml.p3.2xlarge\",\n",
    "        \"InstanceCount\": 1,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fb4974",
   "metadata": {},
   "source": [
    "#### Multiple file batch of 10,000 quotes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ebf30e-bc09-4071-bfbc-84af5a8f4231",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import time\n",
    "\n",
    "session = sagemaker.session.Session()\n",
    "client_sm = boto3.client(\"sagemaker\", region_name=\"us-east-1\")\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    client_iam = boto3.client(\"iam\")\n",
    "    role = client_iam.get_role(RoleName=\"sagemaker_execution_role\")[\"Role\"][\"Arn\"]\n",
    "\n",
    "output_s3_path = f\"s3://{S3_BUCKET}/output_batch\"\n",
    "s3_data_input = f\"s3://{S3_BUCKET}/input_batch/10k_quotes/\"\n",
    "model_name = \"<your_deployed_model_name>\"\n",
    "batch_job_name = f\"quotes-batch-{int(time.time())}-10k\"\n",
    "\n",
    "# lauch batch transform job\n",
    "response = client_sm.create_transform_job(\n",
    "    TransformJobName=batch_job_name,\n",
    "    ModelName=model_name,\n",
    "    BatchStrategy=\"SingleRecord\",\n",
    "    TransformInput={\n",
    "        \"DataSource\": {\n",
    "            \"S3DataSource\": {\n",
    "                \"S3DataType\": \"S3Prefix\",\n",
    "                \"S3Uri\": s3_data_input,\n",
    "            }\n",
    "        },\n",
    "        \"ContentType\": \"application/json\",\n",
    "        \"SplitType\": \"Line\",\n",
    "    },\n",
    "    TransformOutput={\n",
    "        \"S3OutputPath\": output_s3_path,\n",
    "        \"AssembleWith\": \"Line\",\n",
    "        \"Accept\": \"application/json\",\n",
    "    },\n",
    "    TransformResources={\n",
    "        \"InstanceType\": \"ml.g4dn.8xlarge\",\n",
    "        \"InstanceCount\": 2,\n",
    "    },\n",
    ")\n",
    "\n",
    "print(response[\"TransformJobArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5334cb-862c-4c92-97d2-b60375c09e4c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Track Batch Transform Progress\n",
    "\n",
    "Reference: <https://github.com/aws/amazon-sagemaker-examples/blob/main/sagemaker_batch_transform/pytorch_flores_batch_transform/sagemaker_batch_transform_torchserve.ipynb>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e3e9fa-f806-4adb-8665-4f54a2c93c29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "while True:\n",
    "    response = client_sm.describe_transform_job(TransformJobName=batch_job_name)\n",
    "    status = response[\"TransformJobStatus\"]\n",
    "    if status == \"Completed\":\n",
    "        print(f\"Transform job ended with status: {status}\")\n",
    "        break\n",
    "    if status == \"Failed\":\n",
    "        message = response[\"FailureReason\"]\n",
    "        print(\"Transform failed with the following error: {}\".format(message))\n",
    "        raise Exception(\"Transform job failed\")\n",
    "    print(f\"Transform job is still in status: {status}\", end=\"\\r\")\n",
    "    time.sleep(30)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
